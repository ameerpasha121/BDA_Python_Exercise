{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Simple Neural Network with Keras Sequential API***"
      ],
      "metadata": {
        "id": "f8QdGW-45_Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate some random data\n",
        "x_train = np.random.random((1000, 20))  # 1000 samples, 20 features each\n",
        "y_train = np.random.randint(2, size=(1000, 1))  # Binary labels (0 or 1)\n",
        "\n",
        "x_test = np.random.random((200, 20))  # 200 test samples\n",
        "y_test = np.random.randint(2, size=(200, 1))  # Binary labels for testing\n",
        "\n",
        "# Build a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 64 neurons and ReLU activation\n",
        "model.add(Dense(64, activation='relu', input_shape=(20,)))\n",
        "\n",
        "# Add another hidden layer with 32 neurons and ReLU activation\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Add an output layer with 1 neuron and sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJpPAbBG6LWQ",
        "outputId": "49384964-48f1-4f23-f096-6702eb170747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4912 - loss: 0.6979\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5396 - loss: 0.6921\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5344 - loss: 0.6890\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5674 - loss: 0.6834\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5685 - loss: 0.6822\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4967 - loss: 0.6975  \n",
            "Test accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Sequential API to create and train a neural network for classifying the MNIST dataset.***"
      ],
      "metadata": {
        "id": "ske7X0_r33aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: normalize images and one-hot encode labels\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the input (28x28 images) into a vector of size 784\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add a hidden layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add the output layer with 10 neurons (one for each class) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygO844pd3anG",
        "outputId": "b1661051-8cf5-4718-8de9-efd560bc0666"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8644 - loss: 0.4751 - val_accuracy: 0.9539 - val_loss: 0.1607\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1352 - val_accuracy: 0.9647 - val_loss: 0.1176\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0915 - val_accuracy: 0.9670 - val_loss: 0.1033\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.0641 - val_accuracy: 0.9726 - val_loss: 0.0932\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0480 - val_accuracy: 0.9718 - val_loss: 0.0957\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0884\n",
            "Test accuracy: 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Generate random binary classification data\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = to_categorical(np.random.randint(2, size=(1000, 1)), num_classes=2)\n",
        "\n",
        "x_test = np.random.random((200, 20))\n",
        "y_test = to_categorical(np.random.randint(2, size=(200, 1)), num_classes=2)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(20,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # Two classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "print(\"Adam + ReLU:\")\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "H4VP_F0d3paH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be73e729-5c5a-4087-869b-304646867e62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 0.6935\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 0.6892\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: 0.6958\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5695 - loss: 0.6809\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5891 - loss: 0.6700\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5290 - loss: 0.6870\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5605 - loss: 0.6761\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5550 - loss: 0.6795\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6157 - loss: 0.6581\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 0.6427\n",
            "Adam + ReLU:\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5068 - loss: 0.7258  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7154614329338074, 0.5299999713897705]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just replace activation in the hidden layers\n",
        "model = Sequential([\n",
        "    Dense(128, activation='tanh', input_shape=(20,)),\n",
        "    Dense(64, activation='tanh'),\n",
        "    Dense(64, activation='tanh'),\n",
        "    Dense(32, activation='tanh'),\n",
        "    Dense(32, activation='tanh'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Adam + tanh:\")\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcVPfNq8xgOU",
        "outputId": "b407bade-b952-4d4a-d8ef-2b1b0e8605fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam + tanh:\n",
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5063 - loss: 0.7181\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5448 - loss: 0.6847\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5999 - loss: 0.6726\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4978 - loss: 0.7101\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5464 - loss: 0.6834\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5565 - loss: 0.6809\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5679 - loss: 0.6828\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5390 - loss: 0.6896\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6773\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5892 - loss: 0.6648\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5399 - loss: 0.6881  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6854815483093262, 0.5400000214576721]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with SGD\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"SGD + ReLU:\")\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "# Try with RMSprop\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"RMSprop + ReLU:\")\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYgIGEAhxkMU",
        "outputId": "b9e6e0da-54de-4a2b-c484-401e4a025277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD + ReLU:\n",
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.6672\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5961 - loss: 0.6718\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5808 - loss: 0.6727\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.6650\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.6637\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 0.6649\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5958 - loss: 0.6690\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5782 - loss: 0.6703\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5849 - loss: 0.6694\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5923 - loss: 0.6633\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4468 - loss: 0.7021  \n",
            "RMSprop + ReLU:\n",
            "Epoch 1/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.6799\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5888 - loss: 0.6679\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6093 - loss: 0.6674\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6108 - loss: 0.6547\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6368 - loss: 0.6506\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6337 - loss: 0.6512\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6249 - loss: 0.6446\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6008 - loss: 0.6519\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6198 - loss: 0.6542\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6768 - loss: 0.6196\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5294 - loss: 0.7357  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7403872609138489, 0.5199999809265137]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "\n",
        "# Model with 5 hidden layers\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
        "print(\"MNIST + Adam + ReLU:\")\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJVTGV6Wx48l",
        "outputId": "accd9ad7-3553-4ece-c65f-87756c20edfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.8605 - loss: 0.4511 - val_accuracy: 0.9663 - val_loss: 0.1050\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.9691 - loss: 0.1003 - val_accuracy: 0.9677 - val_loss: 0.1150\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9787 - loss: 0.0689 - val_accuracy: 0.9725 - val_loss: 0.0962\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.0510 - val_accuracy: 0.9812 - val_loss: 0.0677\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0385 - val_accuracy: 0.9730 - val_loss: 0.0963\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9891 - loss: 0.0351 - val_accuracy: 0.9798 - val_loss: 0.0790\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0322 - val_accuracy: 0.9815 - val_loss: 0.0698\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0221 - val_accuracy: 0.9805 - val_loss: 0.0704\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0227 - val_accuracy: 0.9798 - val_loss: 0.0761\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.0175 - val_accuracy: 0.9785 - val_loss: 0.0869\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.9817 - val_loss: 0.0797\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.9817 - val_loss: 0.0830\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.9808 - val_loss: 0.0900\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.0127 - val_accuracy: 0.9817 - val_loss: 0.0912\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.0144 - val_accuracy: 0.9812 - val_loss: 0.0857\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.0138 - val_accuracy: 0.9845 - val_loss: 0.0698\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.9792 - val_loss: 0.1181\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.0130 - val_accuracy: 0.9828 - val_loss: 0.0827\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.9822 - val_loss: 0.0920\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9978 - loss: 0.0087 - val_accuracy: 0.9850 - val_loss: 0.0726\n",
            "MNIST + Adam + ReLU:\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.1067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08379518985748291, 0.9818999767303467]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the same model, just change optimizer\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"MNIST + SGD:\")\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"MNIST + RMSprop:\")\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKDWBRe6Mg1z",
        "outputId": "19a934a8-96ee-455c-e6d7-7c8eee38e508"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST + SGD:\n",
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9867 - val_loss: 0.0673\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9872 - val_loss: 0.0676\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9872 - val_loss: 0.0683\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9873 - val_loss: 0.0690\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9873 - val_loss: 0.0698\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9873 - val_loss: 0.0705\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9872 - val_loss: 0.0713\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9872 - val_loss: 0.0720\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9872 - val_loss: 0.0725\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 7.6660e-04 - val_accuracy: 0.9870 - val_loss: 0.0731\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 8.4088e-04 - val_accuracy: 0.9870 - val_loss: 0.0737\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 7.9410e-04 - val_accuracy: 0.9870 - val_loss: 0.0742\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.6349e-04 - val_accuracy: 0.9868 - val_loss: 0.0748\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 6.2241e-04 - val_accuracy: 0.9870 - val_loss: 0.0753\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6179e-04 - val_accuracy: 0.9870 - val_loss: 0.0758\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 6.0384e-04 - val_accuracy: 0.9870 - val_loss: 0.0763\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1675e-04 - val_accuracy: 0.9870 - val_loss: 0.0768\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 4.9809e-04 - val_accuracy: 0.9870 - val_loss: 0.0773\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 4.4935e-04 - val_accuracy: 0.9870 - val_loss: 0.0777\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3843e-04 - val_accuracy: 0.9870 - val_loss: 0.0782\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1133\n",
            "MNIST + RMSprop:\n",
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 8.9001e-04 - val_accuracy: 0.9870 - val_loss: 0.1126\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 3.5266e-04 - val_accuracy: 0.9855 - val_loss: 0.1344\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 1.7718e-04 - val_accuracy: 0.9858 - val_loss: 0.1317\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.3440e-06 - val_accuracy: 0.9862 - val_loss: 0.1326\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.2262e-06 - val_accuracy: 0.9862 - val_loss: 0.1342\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.2400e-07 - val_accuracy: 0.9862 - val_loss: 0.1356\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 1.1220e-06 - val_accuracy: 0.9862 - val_loss: 0.1367\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 8.1234e-07 - val_accuracy: 0.9862 - val_loss: 0.1377\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 1.1104e-06 - val_accuracy: 0.9862 - val_loss: 0.1386\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.3357e-07 - val_accuracy: 0.9862 - val_loss: 0.1395\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.5478e-07 - val_accuracy: 0.9862 - val_loss: 0.1403\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 4.2773e-07 - val_accuracy: 0.9862 - val_loss: 0.1410\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7211e-07 - val_accuracy: 0.9860 - val_loss: 0.1416\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4790e-07 - val_accuracy: 0.9860 - val_loss: 0.1422\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7571e-07 - val_accuracy: 0.9860 - val_loss: 0.1428\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.9347e-07 - val_accuracy: 0.9860 - val_loss: 0.1434\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.3647e-07 - val_accuracy: 0.9860 - val_loss: 0.1439\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 2.7713e-07 - val_accuracy: 0.9860 - val_loss: 0.1444\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5858e-07 - val_accuracy: 0.9862 - val_loss: 0.1448\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.9061e-07 - val_accuracy: 0.9862 - val_loss: 0.1453\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.1867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1481480896472931, 0.9861999750137329]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace all activation='relu' with 'tanh' or 'sigmoid'\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(512, activation='tanh'),  # or 'sigmoid'\n",
        "    Dense(256, activation='tanh'),\n",
        "    Dense(128, activation='tanh'),\n",
        "    Dense(64, activation='tanh'),\n",
        "    Dense(32, activation='tanh'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"MNIST + tanh:\")\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk4_UcY9yqw3",
        "outputId": "7f8c95a2-1fc3-4a7f-ae0c-ece78b6aeaef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST + tanh:\n",
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.8726 - loss: 0.4590 - val_accuracy: 0.9647 - val_loss: 0.1207\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.1418 - val_accuracy: 0.9707 - val_loss: 0.1037\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9704 - loss: 0.1005 - val_accuracy: 0.9703 - val_loss: 0.0965\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9751 - loss: 0.0806 - val_accuracy: 0.9732 - val_loss: 0.0965\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0654 - val_accuracy: 0.9758 - val_loss: 0.0822\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0558 - val_accuracy: 0.9648 - val_loss: 0.1360\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0545 - val_accuracy: 0.9740 - val_loss: 0.0939\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9876 - loss: 0.0399 - val_accuracy: 0.9772 - val_loss: 0.0910\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0381 - val_accuracy: 0.9760 - val_loss: 0.0871\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9898 - loss: 0.0335 - val_accuracy: 0.9752 - val_loss: 0.0942\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.0312 - val_accuracy: 0.9810 - val_loss: 0.0729\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0270 - val_accuracy: 0.9805 - val_loss: 0.0709\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0248 - val_accuracy: 0.9782 - val_loss: 0.0843\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0251 - val_accuracy: 0.9777 - val_loss: 0.0902\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0222 - val_accuracy: 0.9797 - val_loss: 0.0789\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9932 - loss: 0.0212 - val_accuracy: 0.9770 - val_loss: 0.0880\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.9797 - val_loss: 0.0827\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.0157 - val_accuracy: 0.9735 - val_loss: 0.1192\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0231 - val_accuracy: 0.9793 - val_loss: 0.0814\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9936 - loss: 0.0195 - val_accuracy: 0.9772 - val_loss: 0.0942\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1037319004535675, 0.972100019454956]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace all activation='relu' with 'tanh' or 'sigmoid'\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(512, activation='sigmoid'),  # or 'sigmoid'\n",
        "    Dense(256, activation='sigmoid'),\n",
        "    Dense(128, activation='sigmoid'),\n",
        "    Dense(64, activation='sigmoid'),\n",
        "    Dense(32, activation='sigmoid'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"MNIST + tanh:\")\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQJj5MtWytmg",
        "outputId": "18b7b79b-b401-4ebc-eb73-ce0ee0dc90a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST + tanh:\n",
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.5002 - loss: 1.5211 - val_accuracy: 0.9132 - val_loss: 0.3976\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9158 - loss: 0.3620 - val_accuracy: 0.9572 - val_loss: 0.1965\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9492 - loss: 0.2058 - val_accuracy: 0.9652 - val_loss: 0.1445\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9614 - loss: 0.1476 - val_accuracy: 0.9690 - val_loss: 0.1199\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9737 - loss: 0.1043 - val_accuracy: 0.9692 - val_loss: 0.1160\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9779 - loss: 0.0864 - val_accuracy: 0.9728 - val_loss: 0.0982\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0679 - val_accuracy: 0.9758 - val_loss: 0.0957\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0534 - val_accuracy: 0.9750 - val_loss: 0.0908\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0476 - val_accuracy: 0.9807 - val_loss: 0.0751\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9904 - loss: 0.0370 - val_accuracy: 0.9775 - val_loss: 0.0829\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.0310 - val_accuracy: 0.9778 - val_loss: 0.0825\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.9790 - val_loss: 0.0905\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9940 - loss: 0.0229 - val_accuracy: 0.9758 - val_loss: 0.0984\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.0202 - val_accuracy: 0.9767 - val_loss: 0.1018\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.0191 - val_accuracy: 0.9782 - val_loss: 0.0913\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0132 - val_accuracy: 0.9773 - val_loss: 0.1041\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9797 - val_loss: 0.0886\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 0.9775 - val_loss: 0.0910\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.0118 - val_accuracy: 0.9793 - val_loss: 0.1035\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0130 - val_accuracy: 0.9787 - val_loss: 0.1003\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.1155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09600921720266342, 0.980400025844574]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}